import io
import time
from datetime import datetime

import matplotlib.pyplot as plt
import pandas as pd
import streamlit as st
from dotenv import load_dotenv
from langchain.chains.conversation.base import ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain_openai import ChatOpenAI

load_dotenv()


def get_ai_response(memory, user_prompt, system_prompt):
    """æ ¹æ®é€‰æ‹©çš„æ¨¡å‹è·å–AIå“åº”"""
    model = ChatOpenAI(
        model=st.session_state.selected_model,
        base_url='https://twapi.openai-hk.com/v1',
        api_key="hk-mjaz441000055433690fea7d56462f12f3d05d9e764f7c81",
        temperature=st.session_state.model_temperature,
        max_tokens=st.session_state.model_max_length
    )
    chain = ConversationChain(llm=model, memory=memory)
    full_prompt = f"{system_prompt}\n{user_prompt}"
    return chain.invoke({'input': full_prompt})['response']


def extract_chart_type(ai_response):
    chart_keywords = {
        "æŠ˜çº¿å›¾": ["line", "è¶‹åŠ¿", "å˜åŒ–"],
        "æŸ±çŠ¶å›¾": ["bar", "æ¯”è¾ƒ", "åˆ†å¸ƒ"],
        "é¥¼å›¾": ["pie", "æ¯”ä¾‹", "å æ¯”"],
        "æ•£ç‚¹å›¾": ["scatter", "å…³ç³»", "ç›¸å…³æ€§"]
    }
    for chart, keywords in chart_keywords.items():
        for keyword in keywords:
            if keyword in ai_response.lower():
                return chart
    return "æŠ˜çº¿å›¾"


def generate_chart(df, chart_type):
    plt.style.use('ggplot')
    fig, ax = plt.subplots(figsize=(10, 6))
    fig.patch.set_facecolor('#F8F9FF')
    ax.set_facecolor('#F8F9FF')
    colors = ['#2A27C7', '#6C63FF', '#00B4D8']

    try:
        if "æŠ˜çº¿å›¾" in chart_type:
            ax.plot(df.iloc[:, 0], df.iloc[:, 1], color=colors[0], marker='o')
        elif "æŸ±çŠ¶å›¾" in chart_type:
            ax.bar(df.iloc[:, 0], df.iloc[:, 1], color=colors)
        elif "é¥¼å›¾" in chart_type:
            ax.pie(df.iloc[:, 1], labels=df.iloc[:, 0], autopct='%1.1f%%', colors=colors)
        elif "æ•£ç‚¹å›¾" in chart_type:
            ax.scatter(df.iloc[:, 0], df.iloc[:, 1], color=colors[0])
        else:
            st.error(f"ä¸æ”¯æŒçš„å›¾è¡¨ç±»å‹ï¼š{chart_type}")
            return

        ax.set_title(chart_type, fontsize=14, color='#2A27C7')
        if chart_type != "é¥¼å›¾":
            ax.set_xlabel(df.columns[0])
            ax.set_ylabel(df.columns[1])
        ax.grid(True, alpha=0.3)
        plt.xticks(rotation=45)
        st.pyplot(fig)

        buf = io.BytesIO()
        plt.savefig(buf, format='png', bbox_inches='tight')
        st.download_button(
            label="ä¸‹è½½å›¾è¡¨",
            data=buf.getvalue(),
            file_name=f"superai_chart_{datetime.now().strftime('%Y%m%d%H%M')}.png",
            mime="image/png"
        )
    except Exception as e:
        st.error(f"å›¾è¡¨ç”Ÿæˆå¤±è´¥ï¼š{str(e)}")
    finally:
        plt.close()


header_container = st.container()
with header_container:
    cols = st.columns([1, 8, 1])
    with cols[1]:
        st.markdown("""
            <div style="text-align:center; margin-bottom:40px">
                <h1 style="margin-bottom:0">SuperAI æ™ºèƒ½åˆ†æåŠ©æ‰‹ğŸš€</h1>
                <p style="color:#6C63FF; font-size:1.2rem">æ•°æ®æ´å¯Ÿä»æœªå¦‚æ­¤ç®€å•</p>
            </div>
        """, unsafe_allow_html=True)

if 'messages' not in st.session_state:
    st.session_state.messages = [{'role': 'ai', 'content': 'ä½ å¥½ï¼Œæˆ‘æ˜¯ä½ çš„AIåŠ©æ‰‹ï¼Œè¯·é—®æœ‰ä»€ä¹ˆèƒ½å¸®åŠ©ä½ å—ï¼Ÿ'}]
    st.session_state.memory = ConversationBufferMemory(return_messages=True)
    st.session_state.history = []
    st.session_state.df = None
    st.session_state.txt_content = None

with st.sidebar:
    st.title("æ¨¡å‹é…ç½®")

    st.session_state.selected_model = st.selectbox(
        "é€‰æ‹©AIæ¨¡å‹",
        ["gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo", "gpt-4"],
        index=0,
        help="é€‰æ‹©è¦ä½¿ç”¨çš„AIæ¨¡å‹"
    )

    st.session_state.model_temperature = st.slider("æ¸©åº¦ (Temperature)", 0.0, 1.0, 0.7, 0.1)
    st.session_state.model_max_length = st.slider("æœ€å¤§é•¿åº¦", 100, 2000, 1000)
    system_prompt = st.text_area("ç³»ç»Ÿæç¤ºè¯", "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„AIåŠ©æ‰‹ï¼Œç”¨ä¸­æ–‡å›ç­”é—®é¢˜")

    st.subheader("ä¸Šä¼ æ•°æ®æ–‡ä»¶")
    file = st.file_uploader("ä¸Šä¼ CSVã€Excelæˆ–TXTæ–‡ä»¶", type=["csv", "xlsx", "txt"])
    if file:
        try:
            file_type = file.name.split('.')[-1]
            if file_type in ['csv', 'xlsx']:
                df = pd.read_csv(file) if file_type == 'csv' else pd.read_excel(file)
                st.session_state.df = df
                st.dataframe(df.head(8), use_container_width=True, height=300)
                st.caption(f"æ•°æ®ç»´åº¦ï¼š{df.shape[0]} è¡Œ Ã— {df.shape[1]} åˆ—")
            elif file_type == 'txt':
                txt_content = file.read().decode('utf-8')
                st.session_state.txt_content = txt_content
                st.text_area("TXTæ–‡ä»¶å†…å®¹", txt_content, height=300)
        except Exception as e:
            st.error(f"æ•°æ®åŠ è½½å¤±è´¥ï¼š{str(e)}")

    st.subheader("å†å²æ¶ˆæ¯")
    if st.session_state.messages:
        selected_history = st.selectbox(
            "é€‰æ‹©å†å²å¯¹è¯",
            options=[msg["content"][:30] + "..." if len(msg["content"]) > 30 else msg["content"]
                     for msg in st.session_state.messages if msg["role"] == "human"],
            key="history_select"
        )
        if selected_history:
            for idx, message in enumerate(st.session_state.messages):
                if message["role"] == "human" and message["content"].startswith(selected_history[:30]):
                    st.markdown(f"**ç”¨æˆ·**: {message['content']}")
                    if idx + 1 < len(st.session_state.messages):
                        st.markdown(f"**AI**: {st.session_state.messages[idx + 1]['content']}")

    if st.button("æ¸…ç©ºå¯¹è¯å†å²"):
        st.session_state.messages = [{'role': 'ai', 'content': 'ä½ å¥½ï¼Œæˆ‘æ˜¯ä½ çš„AIåŠ©æ‰‹ï¼Œè¯·é—®æœ‰ä»€ä¹ˆèƒ½å¸®åŠ©ä½ å—ï¼Ÿ'}]
        st.session_state.memory.clear()

for message in st.session_state.messages:
    role = "user" if message["role"] == "human" else "assistant"
    with st.chat_message(role):
        st.write(message["content"])

if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    st.session_state.messages.append({'role': 'human', 'content': prompt})

    with st.spinner('AI æ­£åœ¨æ€è€ƒï¼Œè¯·ç¨ç­‰...'):
        progress_bar = st.progress(0)
        response_container = st.empty()
        full_response = ""

        analysis_request = f"åˆ†æè¯·æ±‚ï¼š{prompt}\n"
        if st.session_state.df is not None:
            analysis_request += f"æ•°æ®ç»“æ„ï¼š{st.session_state.df.columns.tolist()}\n"
            analysis_request += f"æ•°æ®ç»´åº¦ï¼š{st.session_state.df.shape}\n"

            # æ ¹æ®æ•°æ®é›†å¤§å°å†³å®šæ˜¯å¦åŒ…å«å®Œæ•´æ•°æ®
            if st.session_state.df.size < 10000:  # å¦‚æœæ•°æ®å¤§å°å°äº10000ï¼ŒåŒ…å«å®Œæ•´æ•°æ®
                analysis_request += f"å®Œæ•´æ•°æ®ï¼š{st.session_state.df.to_csv(index=False)}\n"
            else:
                analysis_request += "æ•°æ®è¾ƒå¤§ï¼ŒæœªåŒ…å«å®Œæ•´æ•°æ®ã€‚\n"
        elif st.session_state.txt_content:
            analysis_request += f"æ–‡æœ¬å†…å®¹ï¼š{st.session_state.txt_content[:1000]}..."

        ai_response = get_ai_response(st.session_state.memory, analysis_request, system_prompt)

        for i in range(len(ai_response)):
            full_response = ai_response[:i + 1]
            response_container.write(full_response)
            progress_bar.progress((i + 1) / len(ai_response))
            time.sleep(0.03)

        st.session_state.messages.append({'role': 'ai', 'content': full_response})
        st.session_state.memory.save_context({'input': prompt}, {'output': full_response})

        if any(keyword in full_response for keyword in ["å›¾è¡¨", "å›¾å½¢", "å¯è§†åŒ–"]):
            chart_type = extract_chart_type(full_response)
            if st.session_state.df is not None:
                generate_chart(st.session_state.df, chart_type)